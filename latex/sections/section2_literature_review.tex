\section{Literature Review} \label{sec: Literature Review}

This section provides an overview of the literature


\subsection{Empirical Properties of Volatility and Limitations of Classical Models} \label{subsec: Empirical Properties of Volatility}

In mathematical finance, classical models of asset prices usually treat volatility either as a deterministic function of time or as a continuous process driven by Brownian motion. In the Black-Scholes framework, volatility is assumed to be constant, while the Heston model \citep{Heston1993} introduces stochastic volatility through a mean-reverting process. However, both models struggle to reproduce some typical features of volatility observed in financial markets. These include volatility clustering, persistent behavior over time, and the characteristic shapes of implied volatility surfacesâ€”such as volatility smiles and skews \citep{Rubinstein1985}. In particular, they fail to capture the power-law behavior of the at-the-money (ATM) volatility skew. As a result, the option prices these models produce often deviate significantly from market prices.

Recent empirical studies, such as \citet{GatheralJaissonRosenbaum2018}, indicate that log-volatility processes behaves similarly to a fractional Brownian motion with a Hurst parameter around $H \approx 0.1$. This means that volatility paths are irregular or \emph{rough}, with strongly negatively correlated increments at short time scales. Classical models are unable to replicate this behavior. In addition, volatility is known to show \emph{long memory}, i.e. the autocorrelations of realized volatility decay slowly over time, indicating persistent effects.

Together, these findings suggest that volatility is both rough and persistent. This has motivated the development of new volatility models that go beyond the classical Markovian setting and aim to better match the observed behavior in financial markets.



\subsection{Fractional and Rough Volatility Models} \label{subsec: Fractional and Rough Volatility Models}

To address the shortcomings of classical volatility models, researchers began exploring stochastic volatility models driven by fractional Brownian motion. Early contributions such as \citet{ComteRenault1998} proposed modeling volatility as a fractional Ornstein--Uhlenbeck process, where the driving noise has long memory properties. These models successfully reproduced persistent volatility dynamics and slow decay in autocorrelations, in line with empirical observations. However, they often relied on a Hurst parameter \( H > 0.5 \), and therefore did not capture the roughness (i.e., \( H < 0.5 \)) identified in more recent studies.

A major step forward came with the introduction of rough volatility models, particularly the rough Bergomi (rBergomi) model proposed by \citet{BayerFrizGatheral2016}. In this model, the volatility process is driven by a fractional Brownian motion with Hurst parameter \( H < 0.5 \), capturing the short-term irregularity of volatility trajectories. The rBergomi model matches the steep skew observed in short-maturity implied volatilities remarkably well, and has become a standard benchmark for rough volatility modeling. However, the model remains difficult to calibrate and simulate, due to its non-Markovian structure and the lack of closed-form solutions.

Another approach is the rough Heston model, introduced by \citet{ElEuchRosenbaum2019}, which extends the classical Heston framework by replacing the standard variance process with a fractional integral of a CIR-type process. This model retains some analytical tractability via generalized Riccati equations and offers a compromise between realism and computational complexity.

While fractional and rough volatility models capture key empirical features of volatility, they often come at the cost of simulation complexity and limited interpretability. In particular, most models are not Markovian, and their calibration requires specialized numerical methods. The Hypergeometric Volatility Model addressed in this thesis aims to overcome these limitations by combining roughness and long memory in a Gaussian but tractable framework based on Laplace-mixed Ornstein--Uhlenbeck processes.
